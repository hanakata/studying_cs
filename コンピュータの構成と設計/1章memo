第1章 コンピュータの抽象化とテクノロジー

■コンピュータアーキテクチャにおける8つの主要アイデア
1.Mooreの法則の設計
  コンピュータ設計者が念頭に置くべき事柄：急速な変化
  Mooreの法則は集積回路の密度が18～24ヶ月ごとに倍増すると基底している。
  コンピュータ設計者は設計開始ではなく終了時点を見定めて設計を行う必要がある。
2.設計を単純化するための抽象化
  コンピュータアーキテクトとプログラマが生産性を高めるための技法を案出し続けなければならない。
  その技法として抽象化が存在する。抽象化＝層別に設計を行うこと。上位のレベルにおいて
  下位レベルの詳細を隠すことでモデルを抽象化することが出来る。
3.一般的な場合を高速化する
  希な場合を最適化するよりも一般的な場合を高速化したほうが性能が向上しやすい。
  この場合、一般的な場合が分かっていることが前提。
4.並列処理による性能向上
  コンピュータの登場以来処理を並行で進めることにより性能を高める設計を進めてきた。
5.パイプライン処理による性能向上
  コンピュータアーキテクチャにはパイプライン処理と呼ばれる並列処理方式がある。
6.予測による性能向上
  先に許可を求めるより、後で許しを請う方が良いということわざ通り。
  予測に基づいて作業を開始する方が平均して早い。
7.記憶階層
  最高速でビットあたりのコストが最も高価な最小容量のメモリを記憶階層の最上部に配置し
  最低速でビットあたりのコストが最も安価な大量のメモリを記憶階層の最下部に配置する。
  そうすることでメモリによって縛られる問題を解決する方法のひとつとなる。
8.冗長性による信頼性向上
  コンピュータは高速であることと信頼性が高いということが重要。
  そのため故障しても動作できる方法として冗長化する。故障を検知することも可能になる。

■プログラムの裏側
代表的なアプリケーションは何百万行ものコードで構成されており、それをサポートする複雑な
機能を備えたソフトウエアライブラリを利用している。
複雑なアプリケーションから単純な命令に至るためにはソフトウエアの層をいくつか経由して
高水準の処理を単純なコンピュータ命令に変換する必要がある。：抽象化
ソフトウエアの層は以下の順に外側から階層化されている。
・アプリケーションソフトウエア
・システムソフトウエア→共通に利用されるサービスやＯＳ、コンパイラ、アセンブラなど。
・ハードウエア

システムソフトウエアに含まれるOSの重要な機能は以下
・基本的な入出力を行う
・外部記憶及びメモリを割り当てる
・コンピュータを同時に使用する複数のアプリの間でコンピュータ資源の共有を図る
コンパイラは以下の機能を有する
・高水準言語をHWが実行できるように翻訳
電子的なハードウェアと情報を交換するためには電子的な信号を送る必要がある。
コンピュータが理解できるのはONとOFF(0か1か)のみ。
01で書くのはきついので記号で書くようになった。
その記号で書かれたプログラムをコンピュータを使って2進数に翻訳するプログラムをアセンブラと呼ぶ。
例えばadd A,Bとなっているものをアセンブラを使って翻訳すると1000110010100000となる。
このadd～となっているのものをアセンブリ言語、01になっているものを機械語と呼ぶ。
ただアセンブリ言語は人が読むには大変なので読みやすい高水準プログラム言語が作成された。
高水準プログラム言語を使うとA+Bと書くことが出来る。
これをコンパイラを利用してコンパイルするとadd A,Bというアセンブリ言語が得られる。
これをアセンブルすると01になる。
高水準言語を利用する利点は以下の通り
・読みやすい
・生産性が向上する
・プログラムをコンピュータから独立させられる

■コンピュータの内部
いかなるコンピュータでもハードウエアは基本的に同じ機能を遂行する。
機能とは？
→データの入力、データの出力、データの処理、データの記憶
コンピュータの主要な2つの構成要素とは？
・入力装置
・出力装置
コンピュータの古典的な5つの構成要素とは入力、出力、記憶、データパス、制御。
データパスと制御をあわせてプロセッサと呼ぶこともある。
出力装置
→液晶ディスプレイ(LCD)
LCDは光源ではなく光の透過量を制御するだけ。
今のLCDはアクティブマトリックスディスプレイ技術が使われている。
→電圧を精密に制御して画像を鮮明にするためのスイッチがピクセルごとにある。
画像はピクセルのマトリクスで構成される。これで描いた画像をビットマップと呼ぶ。
グラフィックディスプレイを支える主要ハードウェアは以下
・ラスターリフレッシュバッファ
画面上に表示される画像がラスターリフレッシュバッファ中にビットマップの形式で格納される。

タッチスクリーンは最近のものだと静電容量方式が用いられている。
静電容量が変わることにより触れたことを検知する。
この方法であれば複数の箇所を同時に操作することが出来る。
そうすることでジェスチャ操作が可能になる。

今どきのPC(iPad)では入出力が大半でデータパス、メモリ、制御はほんの一部。
それぞれの要素と役割
・プロセッサ：プログラムの命令に従って動く。内部はデータパスと制御に分かれる
・データパス：手足であり演算処理を行う。
・制御：神経でありプログラムの命令に従って何をするかデータパスとメモリと入出力に指示する。
・メモリ：実行中のプログラムと必要とするデータを格納する。最近はDRAMチップで構成されている。
  DRAM=ダイナミックRAM。記憶保持動作の要る随時読み出し書き込み可能なメモリ。
       テープは順を追って読み出す必要があるがメモリはどこでも読み出す時間は同じ。
  キャッシュメモリ：バッファの働きをする小さなメモリ。スタティックRAMを使用して作られている。
設計を改善する主要なアイデアは抽象化。
抽象化の1つはハードウエアと最低水準のソフトウエアのインターフェース＝命令セットアーキテクチャ(アーキテクチャ)
この命令セットはアプリケーションを作成する上で知っておかなければならないこと。
ただOSによってカプセル化されているので詳細に心配する必要はない。
アプリケーションの基本命令セットとオペレーティングシステムインターフェースとの組み合わせ＝アプリケーション・バイナリ・インターフェース
アーキテクチャの実装方式：抽象化されたアーキテクチャに基づくハードウエア。

ハードウェアもソフトウエアも一連の階層から構成されている。下位階層は上位階層から細目を隠す働きをしている。
これによりコンピュータシステムの複雑さに対処することが出来る。
抽象化の中で最も重要なのが命令セットアーキテクチャ。
これのおかげでコストや性能が違っても同じソフトウエアの実行が可能となる。

コンピュータ内部は基本揮発性メモリなので電源が切れるとデータが失われる。
失わないように不揮発性メモリを利用する。HDDとか。
実行中のプログラムとか＝揮発性メモリ＝主記憶、一次記憶：DRAM主流
実行していないプログラムとか＝不揮発性メモリ＝二次記憶：磁気ディスク、フラッシュメモリ
2次記憶は記憶階層の次の下位層を形成する。

次はネットワーク。
今どきネットワークインターフェースがなければ笑いもの。
ネットワークに接続することで得られる利点は以下。
・通信：コンピュータ間での情報交換
・資源の共有：複数のコンピュータで入力を共有できる。
・リモートアクセス：遠隔地のコンピュータへの接続
ネットワークにはLANとかWANがある。

■プロセッサおよびメモリを製造するための技術
トランジスタ：電気的なオン/オフ動作するスイッチ
集積回路：数十から数百のトランジスタを1チップにまとめて接続したもの
超大規模集積回路(VLSI)：数百万規模のトランジスタ

チップはシリコンから製造される。
シリコンは電気を中程度しか通さないので半導体と呼ばれる。
シリコンに化学処理を加えると以下の性質のどれかを持たせることが出来る。
・電気を良く通す（導体）
・電気をよく絶縁する（絶縁体）
・特定条件に応じて電気を通したり通さなかったりする（スイッチ的なやつ）
トランジスタはスイッチ的なやつに属する。
集積回路の製造工程は以下
シリコン結晶インゴット→輪切り→無地のウェーハ→一連の加工を施して絶縁体と導体とトランジスタを作る
ウエーハに傷があった場合、傷のある部分は不良品となる。
完全なウエーハを作成するのは製造上不可能なため構成要素単位に切り出しチップに分けて配置する。
どこか傷があればそこだけ変えればよい。
良品のダイを選別して入出力ピンに接続する。->ボンディングと呼ぶ

■性能
性能的に優れているとするならば性能とは何かを定義する必要がある。
個人のPCユーザであれば応答時間（実行時間）のより短い方が性能高。
コンピュータ管理者であれば多くの処理を終了させた方が性能高。

以下の場合スループットと応答時間はどうなるか
1.コンピュータプロセッサを高速なものに変えた場合
2.複数プロセッサを利用してタスクを分担しているシステムにプロセッサを追加した場合

1の場合応答時間とスループットは改善する。
2の場合タスクが早く終わるわけではないのでスループットだけが増大する。
処理能力よりも仕事量が多かった場合、待ち行列中で待つ時間が短くなるので応答時間も改善する。
性能は以下の式で表すこととする。
性能＝1/実行時間

プログラムの実行時間計測は難しい。
最も簡単な方法は経過時間を測定すること。素直にプログラム実行時間を計測すると
CPUのタイムシェアリング方式で動作した場合、実際の実行時間は分からない。
なので実際にCPUが処理した時間を計測時間とする。それをCPU時間と呼ぶ。
CPU時間はプログラムを実行している時間とOSがタスクを遂行するために利用した時間が存在する。
前者をユーザCPU時間、後者をシステムCPU時間と呼ぶ。
プログラムの性能を引き出すためには問題となる性能の尺度を明確に定義し実行して計測する。
計測した結果、遅い箇所を修正する。

コンピュータはほとんどクロックに基づいて動作を行う。
クロックはHW内で事象を起こすタイミングを決定する。その時間間隔をクロックサイクル時間と呼ぶ。
あるプログラム実行時間を表す式は以下の通り
プログラムCPU実行時間＝CPUクロックサイクル数×クロックサイクル時間
クロックサイクル時間はクロック周波数の逆数なので以下のようにも出来る。
CPU実行時間＝CPUクロックサイクル数/クロック周波数
ハードウェア設計者が性能を向上させたいならクロックサイクル長を短縮するか
プログラムが必要とするクロック数を減らせばよい。

プログラムに必要なクロックサイクル数は以下の式で求められる。
CPUクロックサイクル数＝プログラムの実行命令数×命令あたりの平均クロックサイクル数
命令あたりの平均クロックサイクル数は各命令を実行するのに必要なクロックサイクル数の平均（CPI）

性能に関する公式を実行命令数、CPI、クロックサイクル時間によって求める式は
CPU時間＝実行命令数×CPI×クロックサイクル時間
クロック周波数はクロックサイクル時間の逆数なので以下の式になる。
CPU時間＝実行命令数×CPI/クロック周波数

必要な値を知る方法とは
・CPU時間：実行すれば分かる
・クロックサイクル時間：メーカサイトに行けば分かる
・実行命令数、CPI：クロック周波数と実行時間から算出する

実効命令数の測定はツールがあったりする。
CPIはHWやアプリケーションのつくりによって大きく変わる。

プログラムの性能はアルゴリズム、言語、コンパイラ、アーキテクチャによって変わる。
それぞれ何に影響するかは以下。

アルゴリズム・・・命令数、場合によってCPI
言語・・・命令数、CPI
コンパイラ・・・命令数、CPI
アーキテクチャ・・・命令数、クロック周波数、CPI

■電力の壁
性能も消費電力もPentium4あたりで頭打ち。
それはプロセッサの冷却能力に制約があるから実質的に電力の限界にぶつかったから。
トランジスタ当たりの必要な電力は切り替えエネルギーと切り替え周波数の積で求められる。
切り替え周波数はクロック周波数の関数である。
トランジスタ当たりの容量性負荷は出力に接続されるトランジスタの数および配線とトランジスタの両方の
静電容量を決定する製造テクノロジという2つの要因の関数。
現在の問題は電圧を今以上に下げると漏洩電流が増えること。現時点で消費電力の40%は漏洩電流。

■方向転換：単体プロセッサからマルチプロセッサ
電力の壁にぶつかったので今までの単体プロセッサからマルチプロセッサに切り替え。
ハードウエアとソフトウエアのインターフェースとして並列処理はコンピュータ処理の
性能にとって常に重要。例えばパイプライン処理は命令レベルの並列性を利用した例。
ハードウェアの限界を向かえている現在において処理速度を上げるには並列プログラムが必要。
ただし難しい。
例えば、スケジューリングや意思疎通および同期のオーバーヘッドを考慮する必要がある。

■実例：Intel Core 7iのベンチマークテスト
※割愛

■誤信と落とし穴
落とし穴：コンピュータのある面を改善することによってその改善度に等しい性能向上を期待すること
ある面を改善したことによる性能の向上はその改善された機能が使用される割合に制約される。
落とし穴：コンピュータの利用率が低ければ消費電力は少ない
現状、そういったことはない。
誤信：性能を上げる設計とエネルギー効率を上げる設計とは目標的に無関係である。
エネルギーは電力と時間の積。なので時間を短縮するよう最適化するとエネルギー節約になる。
落とし穴：性能の尺度に性能方程式の一部をしようすること。
誤解を招く主張、結果の曲解に繋がる。
