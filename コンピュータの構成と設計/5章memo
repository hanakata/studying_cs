5章 容量と速度の両立：記憶階層の利用

論文を書くときに大量な本を必要とするが、それを毎回本棚にとりに行くのは
非効率的なので必要な本を何冊か選んで机の上に置いておく方が楽。
→局所性の法則
局所性には以下の側面がある
・時間的局所性
  →ある項目が参照されすぐにもう一度参照される確率が高い
・空間的局所性
  →ある項目が参照された場合、そこの近くにある項目も参照される確率が高い。

■メモリ・テクノロジ
記憶階層を構成するために使用される主要テクノロジは以下
・SRAM＝CPUに近いDRAM
→配列上の記憶構造をした集積回路。通常読み書きするアクセスポートが1つだけ備えられている。
 アクセス時間は一定。ただし読み出しアクセスと書き込みアクセスは異なる。
 特徴としてリフレッシュする必要がない。
・DRAM＝メモリ
→セル内に保持される値はキャパシタ内に電荷として蓄えられる。その電荷にアクセスするためには
 単一のトランジスタが必要。このアクセスは読み出し、書き込みに使われる。
 電荷を永遠に保持することは出来ずどこかでリフレッシュする必要がある。
 リフレッシュする方法は内容を読み出して書き込むだけ。
 DDR=ダブルデータレート
・フラッシュメモリ
→電気的に消去書き込み可能な読出し専用メモリの一種。DRAM等と異なり書き込みを行うとビットが磨耗する。
 そのため複数書き込みが行われているブロックへの書き込みをアクセスが少ないブロックへ振り返る。
 このことをウェアレベリングと呼ぶ。
・磁気ディスク（ディスクメモリ）
→数枚のプラッタで構成され毎分5400回転から15000回転する。
 磁気体はカセットやビデオのテープと同じ。
 ディスク上のデータは可動アームに付けられた読み書きヘッドと呼ばれる電磁コイルで読み取る。浮いてないとダメ。
 ディスクは同心円に分けられそれをトラック、トラックをさらに分割したものをセクターと呼ぶ。

■キャッシュの基礎
キャッシュ＝調べる必要のあるものを置いておく安全な保存場所
キャッシュについての疑問
・データ項目がキャッシュにないとどうやって判断するか
・キャッシュにない場合、データ項目をどうやって見つけ出すのか
ある語がキャッシュに収められる場所が決まっていればそこを見れば良い
→ダイレクトマップ方式
キャッシュ内にあるかはタグをつけることで実装可能。

制御ユニットはミスを検出した場合、メモリか下位のキャッシュからデータを持ってくる必要がある。
キャッシュミスの処理はプロセッサの制御ユニットとそれとは別の制御ユニットの連携で行われる。
キャッシュミスに対応して踏むべきステップは以下
1.元のPC値（PCー4）をメモリに送る
2.主記憶から読出しを行うよう指示しその完了を待つ
3.キャッシュの該当するブロックに書き込みを行う。
4.命令実行を最初のステップから再開する。

書き込みの場合、キャッシュにある内容と主記憶の内容が別になる場合がある。
そういうとき一貫性をなくしたという。
一貫性をなくさない最も簡単な方法はキャッシュと主記憶両方に書き込むこと＝ライトスルー
→問題点は性能が落ちること
主記憶に対する書き込み待ちのデータを一時蓄えておく。主記憶に書き込むと書き込み待ちを消す＝ライトバッファ
→バッファが満杯の場合解放されるまで待つ必要があるので状況によってかなり遅くなる場合がある。
書き込みが発生したとき新しい値はキャッシュ内の対応ブロックに書き込む＝ライトバック
→実装が複雑

■キャッシュの性能の測定と改善
キャッシュ性能を改善する方法は以下
・マルチレベルキャッシュ＝記憶の階層を1つ増やしてミスペナルティを減らす方法

CPU時間は2つに分けられる
・実行時間
・待ち時間
メモリストールクロック数が増えるとCPU時間は増える。
そのメモリストールクロック数が増える主な原因はキャッシュミス。
メモリストローククロック数は読出しと書き込みの総数。

CPUの性能を上げたとしても周波数が変わらないとか記憶システムを変えていないことによる
性能低下は発生する。

メモリブロックをキャッシュ内の任意のロケーションに保存する方法＝フルアソシアティブ
→柔軟性が高いためキャッシュミスの頻度が減る。ただし保存場所を検索する時に全てを検索する必要があるため
 時間がかかる。
いくつかのセットを作成しそのセット内のキャッシュに任意てきに保存する＝セットアソシアティブ
→セットの中のみ検索すれば良いので全部検索するよりは効率が良い。
 検索方法はキャッシュ中のブロックにアドレスタグを付けておき、そのタグと一致するかセット内を検索する。

置き換え対象ブロックの選択としてダイレクトマップ方式のキャッシュでミスが発生した場合、
全てを置き換えるしかない。
アソシアティブ方式の場合は全てのブロックが置き換え候補となる。
セットアソシアティブの場合はセット単位で置き換え候補が決まる。
置き換えの一般的な方法はLRU法と呼ばれる最も使用されずにいた時間が長いものを選んで置き換える方法

現代のコンピュータは全てキャッシュを利用している。
一次キャッシュでミスが分かった場合、二次キャッシュにアクセスする。そこでもミスしていれば主記憶へのアクセスとなる。

■信頼性の高い記憶階層
信頼性のひとつのアイデア＝冗長

障害の定義
・サービス遂行：仕様どおりサービスが提供されている
・サービス中断：提供されるサービスが仕様から外れている
サービス中断状態を障害とする

コンポーネントの故障による障害によって起こるサービス中断時間を短くする方法は以下
・故障回避：原因を元から絶つ
・故障許容：故障が発生してもサービスを中断させないようにする
・故障予測：故障の発生箇所と発生時期を予想して故障する前に交換する

■仮想マシン
一般的に仮想化にかかるコストは負荷の性質による。
ユーザレベルのプログラムの場合であればあまり負荷はかからない。
入出力の多いものはOSにかかるものが多いので負荷がかかる。

VMMはゲストにソフトウエアインターフェースを提供しゲストの状態を相互に分離しゲストソフトウエアから
自己を保護しなければならない。

命令セットアーキテクチャの設計時点でVMが考慮に入っている場合はVMMが実行しなければならない命令の数を減らし
エミュレーション速度を高めること自体はさほど難しくない。
ただデスクトップやサーバの命令セットは考慮せずに作成されている。
そういった場合、なにかデリケートな情報の読み書きをしようとするとトラップされるので性能が落ちる。

■仮想記憶
仮想記憶＝主記憶にキャッシュ機能を持たせるもの
仮想マシンを利用する際に仮想マシン同士が利用するものでもある。
そのため他のマシンが利用しているキャッシュを破壊するような動作をしないようにする必要がある。
仮想記憶のミス＝ページフォールト
仮想記憶においてミスペナルティはかなり大きい

仮想ページの有効ビットがオフであるとそのページがアクセスされたら例外が発生する。

スワップ空間＝プロセスを作成するときにそのプロセスのすべてのページ用の領域を
フラッシュメモリまたはディスク上に持つ場所

キャッシュへのアクセス時間と主記憶へのアクセス時間の差は少ないためライトスルー方式が利用できると思うが
ただし書き込みにかかる時間をプロセッサに対して隠す必要があるためライトバック方式を使う必要がある。

アドレス変換バッファ＝TLB
メモリ参照の動き
TLBの中で仮想ページ番号を検索する
ヒットすれば物理ページ番号を使用してアドレスを生成し対応する参照ビットをオンにする。
ミスした場合、TLBミスかページフォールトなのかを判断する必要がある。
TLBミスが発生した場合はビットをページテーブルのエントリにコピーして戻す必要がある→ライトバック方式が最適

■記憶階層間に共通する概念
設問1：ブロックをどこに配置できるか
配置方式は以下
・ダイレクトマップ方式
・セットアソシアティブ方式
・フルアソシアティブ方式
連想度を上げると一般にミス率が低下する。
→同一ロケーションに対するエントリの競合が減るため
キャッシュ容量を増やすとミスは減る→そもそもミスが発生しづらいため
連想度を上げるとコストが上がる

設問２：ブロックをどのようにして見つけるか
見つけ方は配置次第
仮想記憶システムにはほとんどフルアソシアティブ方式を利用する。
理由は以下
・ミスのコストが高い
・ミス率を下げるように設計したブロック置き換え方式をソフトウエアで実装できる
・ハードウエアの追加や検索が不要でインデックス付けが可能

設問３：キャッシュミスが発生したときにどのブロックを置き換えたらよいか？
フルアソシアティブ方式→全てのブロックが置き換え候補
セットアソシアティブ方式→該当のセットの中からブロックを選択
ダイレクトマップ方式→一つしかない。

設問４：書き込みはどのように行うか？
ライトスルー：データはキャッシュ中のブロックと下位レベルの記憶階層中のブロック両方に書き込まれる
ライトバック：キャッシュ中のブロックのみ書き込まれる

３Cモデルは全てのミスを下記３つに分類する
・初期参照ミス：キャッシュに読み込まれていないものを読み込んだときに発生するキャッシュ
  対処：ブロックサイズを大きくする
・容量製ミス：プログラムを実行するときに必要となるブロックをキャッシュに収容できないことに起因するキャッシュ
  対処：ブロックサイズを大きくする
・競合性ミス：複数のブロックが同じセットをめぐって競合発生するミス
  対処：連想度を上げる

■有限状態機械を用いた単純なキャッシュの制御
ステートは4つ
・アイドル
・タグ比較
・アロケート
・ライトバック

■並列処理と記憶階層：キャッシュコヒーレンス
プロセッサが同じ物理アドレス空間を共有する可能性が高い場合、2つの異なるプロセッサがメモリ参照する値が
違ってくる可能性がある。→別々のキャッシュからメモリ参照する値を取り出すため。
→キャッシュコヒーレンス問題（コヒーレンス＝一貫性）

キャッシュコヒーレンスがあるマルチプロセッサの場合以下の機能を兼ね備えている
・移行：データ項目を自動的にローカルキャッシュに移しローカルで使用できないようにする

・複製：各ローカルキャッシュにデータ項目のコピーを作成する。

コヒーレンスを実現するためにはデータ項目を書き込む前にデータ項目に対するアクセス権をプロセッサが排他的に占有すること。
→ライトインバリデートプロトコル

■誤信と落とし穴
落とし穴：プログラムを組んだりコンパイラでコードを生成したりする際に記憶システムの動作を無視すること
落とし穴：キャッシュをシミュレーションする際にバイトアドレシングやキャッシュのブロックサイズを計算に入れ忘れること
落とし穴：共有キャッシュの場合にそのキャッシュを共有しているコアまたはスレッドの数よりもセットアソシアティブ方式の連想度を小さくすること
落とし穴：アウトオブオーダー方式のプロセッサの記憶階層を評価するのに平均メモリアクセス時間を使用すること
落とし穴：それまでセグメント化されていなかったアドレス空間の上にセグメントを追加してアドレス空間を拡張すること
誤信：現場環境でのディスクの故障率は仕様に合致している
誤信：OSはディスクへのアクセスをスケジューリングする最善の場所である
落とし穴：仮想化できるように設計されていない命令セットアーキテクチャ上で仮想マシンモニターを実現すること


